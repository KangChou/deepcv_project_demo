# deepcv_project_demo 海量学习资料收藏

我的博客学习技术共享网站：https://blog.csdn.net/weixin_41194129?type=blog

docker Windows数据可视化使用方法：[docker_use.md](https://github.com/KangChou/deepcv_project_demo/blob/main/docker_use.md)

带注意力的图像分类:https://blog.paperspace.com/image-classification-with-attention/


# 比较流行的部署深度学习模型的方法（比较宽泛的说法）
```

通过网络 API 或者预测服务的形式将模型部署在云上，可以使用 Google Cloud、Amazon Web Services、Microsoft Azure 等云服务。
使用 TensorFlow Serving 框架进行部署。
部署在 Docker 容器中。
使用 Flask 框架搭建 web 服务器，并通过 HTTP 请求来调用模型。
将模型部署在边缘设备上，如手机、摄像头等。
使用桌面应用程序的形式部署模型，如使用 Tkinter 或 PyQt 等 GUI 库开发桌面应用。
部署在移动应用程序中，如使用 Android 或 iOS 开发移动应用。
使用 Google Colab、Kaggle 等云端 Jupyter Notebook 环境来调用模型。
通过 REST API 的形式将模型部署在网络上。
使用 Serverless 架构，如 AWS Lambda、Google Cloud Functions 等。
将模型部署在智能音箱或智能手表等可穿戴设备上。
通过命令行工具的形式调用模型。
使用桌面小部件的形式部署模型，如使用 Electron 框架开发桌面小部件。
将模型部署在游戏中。

进一步介绍：
将模型打包成 RESTful API 接口，可以使用 Flask、Django 等 web 框架来实现。
将模型打包成命令行工具或者本地库，可以使用 Python 的 setuptools 库来实现。
将模型打包成 Docker 镜像，可以使用 Docker 来实现。
将模型部署在云平台上，可以使用 Google Cloud Platform、Amazon Web Services 等云平台来实现。
将模型部署在移动设备上，可以使用 TensorFlow Lite、Core ML 等工具来实现。
使用 TensorFlow Serving 进行模型部署
使用 Flask 框架将模型打包成 API
使用 GPU 服务器，如 AWS p3/p2、GCP n1-highmem-8 等，进行模型部署
在云平台上使用容器化解决方案，如 Docker、Kubernetes 进行模型部署
使用 Google Cloud ML Engine 进行模型部署
将模型部署到微服务架构中
使用 TensorFlow Lite 将模型部署到移动端
使用 ONNX 将模型转化为可以在多种平台上运行的格式，然后进行模型部署
使用 Amazon SageMaker 进行模型部署
使用 Microsoft Azure 机器学习服务进行模型部署
使用常见的 Web 框架，如 Django、Flask、Ruby on Rails 等，进行模型部署
使用 TensorFlow.js 将模型部署到网页上
将模型部署到小型边缘设备上，如 Raspberry Pi
使用 Streamlit 快速构建可视化界面，方便模型部署
使用 FastAPI 快速构建 API，方便模型部署
使用 Alibi 包进行模型解释和可视化，方便模型部署
使用 TensorFlow Extended (TFX) 进行端到端的机器学习流程管理和模型部署
使用 Google Cloud Functions 进行模型部署


```





# 常见模型部署工具


```
TensorFlow Serving
Flask
Django
PyTorch Serving
ONNX Runtime
Seldon Core
Kubeflow
Clipper
Ray Serve
Neural Net Playground
TensorFlow Hub
TensorFlow.js
TensorFlow Lite
OpenCV
Keras.js
CoreML
ML Kit
TensorFlow Serving with Docker
TensorFlow Serving with Kubernetes
TensorRT

常见部署工具地址：
TensorFlow Serving：https://github.com/tensorflow/serving
NVIDIA TensorRT：https://github.com/NVIDIA/TensorRT
ONNX Runtime：https://github.com/microsoft/ONNXRuntime
MLFlow：https://github.com/mlflow/mlflow
Seldon Core：https://github.com/SeldonIO/seldon-core
Clipper：https://github.com/ucbrise/clipper
MLModelScope：https://github.com/mlmodelscope/mlmodelscope
Kubeflow：https://github.com/kubeflow/kubeflow
Neural Network Intelligence（NNI）：https://github.com/Microsoft/nni
TensorFlow Model Garden：https://github.com/tensorflow/models
MLKit：https://github.com/mlkit/mlkit
TensorFlow Lite：https://github.com/tensorflow/tensorflow
NVIDIA DALI：https://github.com/NVIDIA/DALI
Hugging Face Transformers：https://github.com/huggingface/transformers
TensorFlow Datasets：https://github.com/tensorflow/datasets
TensorFlow Probability：https://github.com/tensorflow/probability
Tensor2Tensor：https://github.com/tensorflow/tensor2tensor
TensorFlow Hub：https://github.com/tensorflow/hub
TensorFlow Addons：https://github.com/tensorflow/addons
TensorFlow Model Analysis：https://github.com/tensorflow/model-analysis

```

